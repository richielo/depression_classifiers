{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi\\Anaconda3\\envs\\python35\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\richi\\Anaconda3\\envs\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import statistics\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import text_features_extractor as tfExtractor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.layers import Dense, Input, LSTM, Bidirectional, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import tensorflow\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import pickle\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "import modelCreator as mCreator\n",
    "import lvExtractor as le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 10\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\richi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.945 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "C:\\Users\\richi\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before empty list deletion\n",
      "(804,)\n",
      "(804,)\n",
      "After empty list deletion\n",
      "(801,)\n",
      "(801,)\n"
     ]
    }
   ],
   "source": [
    "#Read in the csv\n",
    "chinDataDf = pd.read_csv(\"data_with_features/chin_cleaned_data_f.csv\", encoding='UTF-8')\n",
    "#Only take the text and sentiment columns\n",
    "chinDataDf = chinDataDf[['text', 'depressed']]\n",
    "#Cleaning\n",
    "for index, row in chinDataDf.iterrows():\n",
    "    #Preprocessing\n",
    "    chinText, engText = tfExtractor.splitChinEng(row['text'])\n",
    "    text = tfExtractor.chinPreprocessing(chinText)\n",
    "    chinDataDf.set_value(index,'text',text)\n",
    "#Convert data to numpy array\n",
    "X = np.array(chinDataDf['text'].tolist())\n",
    "iCount = 0\n",
    "deleteIndex = []\n",
    "for wList in X:\n",
    "    if(wList == []):\n",
    "        deleteIndex.append(iCount)\n",
    "    iCount += 1\n",
    "Y = np.array(chinDataDf['depressed'].tolist())\n",
    "#Convert -1 label to 0\n",
    "i = 0\n",
    "for label in Y:\n",
    "    if(label == -1):\n",
    "        Y[i] = 0\n",
    "    i += 1\n",
    "print(\"Before empty list deletion\")\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "X = np.delete(X, deleteIndex)\n",
    "Y = np.delete(Y, deleteIndex)\n",
    "print(\"After empty list deletion\")\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnModel =mCreator.createCnnMcModel(584, topWords)\n",
    "lexCnnModel = mCreator.createLexCnnMcModel(5000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_MC model for Chinese data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer fitting is complete\n",
      "Number of words: 31152\n"
     ]
    }
   ],
   "source": [
    "#Original number of words: 46708\n",
    "#Set top words\n",
    "topWords = 5000\n",
    "#Tokenizing the data\n",
    "tokenizer = Tokenizer(num_words=topWords)\n",
    "xString = []\n",
    "for text in X:\n",
    "    xString.append(' '.join(text))\n",
    "tokenizer.fit_on_texts(xString)\n",
    "print(\"tokenizer fitting is complete\")\n",
    "xSeq = tokenizer.texts_to_sequences(xString)\n",
    "wordIndex = tokenizer.word_index\n",
    "print(\"Number of words: \" + str(len(wordIndex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review mean length: 274.44943820224717\n",
      "maximum review length: 584\n",
      "Done padding\n"
     ]
    }
   ],
   "source": [
    "#Get review mean length\n",
    "lengths = [len(i) for i in xSeq]\n",
    "print(\"review mean length: \" + str(np.mean(lengths)))\n",
    "#Set maximum review length to cover at least 90% of review content\n",
    "maxReviewLength = int(np.percentile(lengths, 90))\n",
    "print(\"maximum review length: \" + str(maxReviewLength))\n",
    "length = maxReviewLength\n",
    "vocab_size = topWords\n",
    "#Set paddings for review data\n",
    "xPadded = pad_sequences(xSeq, maxlen=maxReviewLength)\n",
    "print(\"Done padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning batch size and epoch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xPadded, Y, test_size=0.2, shuffle=True, random_state=i, stratify=Y)\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=mCreator.createCnnMcModel,length=maxReviewLength, vocab_size=topWords, verbose=2)\n",
    "# define the grid search parameters\n",
    "batch_size = [1,5,10, 20, 40, 60, 80, 100]\n",
    "epochs = [10,20,30,40, 50,60,70,80,90, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit([xTrain,xTrain,xTrain,xTrain], yTrain)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session: 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 584)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 584)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 584)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 584)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 584, 50)      250000      input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 584, 50)      250000      input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 584, 50)      250000      input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 584, 50)      250000      input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 583, 100)     10100       embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 582, 100)     15100       embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 581, 100)     20100       embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 580, 100)     25100       embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 583, 100)     0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 582, 100)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 581, 100)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 580, 100)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 291, 100)     0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 291, 100)     0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 290, 100)     0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 290, 100)     0           dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 29100)        0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 29100)        0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 29000)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 29000)        0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 116200)       0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           1162010     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            11          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,232,421\n",
      "Trainable params: 2,232,421\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      " - 15s - loss: 0.6403 - acc: 0.6547\n",
      "Epoch 2/30\n",
      " - 13s - loss: 0.4166 - acc: 0.7891\n",
      "Epoch 3/30\n",
      " - 13s - loss: 0.2780 - acc: 0.9375\n",
      "Epoch 4/30\n"
     ]
    }
   ],
   "source": [
    "cnnAccuracy = []\n",
    "cnnPR = []\n",
    "cnnRecall = []\n",
    "for i in range(1):\n",
    "    print(\"Training session: \" + str(i))\n",
    "    #Split data into training and test set (80%/20%)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xPadded, Y, test_size=0.2, shuffle=True, random_state=seed, stratify=Y)\n",
    "    #Create model\n",
    "    cnnModel =mCreator.createCnnMcModel(maxReviewLength, topWords)\n",
    "    \n",
    "    # Fit the model\n",
    "    cnnModel.fit([xTrain, xTrain, xTrain, xTrain], yTrain, epochs=30, batch_size=3, verbose=2)\n",
    "    # Final evaluation of the model\n",
    "    cnnscores = cnnModel.evaluate([xTest,xTest,xTest, xTest], yTest, verbose=0)\n",
    "    yPred = cnnModel.predict([xTest, xTest, xTest, xTest])\n",
    "    yPredNorm = []\n",
    "    for p in yPred:\n",
    "        if p > 0.5:\n",
    "            yPredNorm.append(1)\n",
    "        else:\n",
    "            yPredNorm.append(0)\n",
    "    cnn_average_precision = average_precision_score(yTest, yPred)\n",
    "    cnn_recall_score = recall_score(yTest, yPredNorm, average='binary')\n",
    "    print(\"Accuracy: %.2f%%\" % (cnnscores[1]*100))\n",
    "    print('Average precision score: {0:0.2f}'.format(cnn_average_precision))\n",
    "    print('Recall score: {0:0.2f}'.format(cnn_recall_score))\n",
    "    cnnAccuracy.append(cnnscores[1])\n",
    "    cnnPR.append(cnn_average_precision)\n",
    "    cnnRecall.append(cnn_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_mean_ac = float(sum(cnnAccuracy))/float(len(cnnAccuracy))\n",
    "cnn_mean_pr = float(sum(cnnPR))/float(len(cnnPR))\n",
    "cnn_mean_recall = float(sum(cnnRecall))/float(len(cnnRecall))\n",
    "print(\"Overal CNN MC result\")\n",
    "print(\"accuracy: \" + str(cnn_mean_ac))\n",
    "print(\"precision score: \" + str(cnn_mean_pr))\n",
    "print(\"recall: \" + str(cnn_mean_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get lexicon embedding\n",
    "lexEmbeddings = []\n",
    "lexProcessCount = 0\n",
    "for wList in X:\n",
    "    if(len(wList) > maxReviewLength):\n",
    "        text = ''.join(wList[0:maxReviewLength])\n",
    "    else:\n",
    "        text = ''.join(wList)\n",
    "    lexEmbedding = le.getLexiconVector(text)\n",
    "    lexEmbeddings.append(lexEmbedding)\n",
    "    lexProcessCount += 1\n",
    "    #print(\"Count: \" + str(lexProcessCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxDim: 7283\n"
     ]
    }
   ],
   "source": [
    "#Perform padding \n",
    "#Get max\n",
    "maxDim = lexEmbeddings[0].shape[0]\n",
    "for l in lexEmbeddings:\n",
    "    if(l.shape[0] > maxDim):\n",
    "        maxDim = l.shape[0]\n",
    "print(\"MaxDim: \" + str(maxDim))\n",
    "for i in range(len(lexEmbeddings)):\n",
    "    diffDim = maxDim - lexEmbeddings[i].shape[0]\n",
    "    if(diffDim > 0):\n",
    "        while(diffDim > 0):\n",
    "            padVec = np.zeros([10,1])\n",
    "            lexEmbeddings[i] = np.vstack((lexEmbeddings[i], padVec[None]))\n",
    "            diffDim -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check for same dim\n",
    "for l in lexEmbeddings:\n",
    "    if(l.shape[0] == topWords):\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Something is wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session: 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 7282, 100)    2100        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 7281, 100)    3100        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 7280, 100)    4100        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 7279, 100)    5100        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7282, 100)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7281, 100)    0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 7280, 100)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7279, 100)    0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 3641, 100)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 3640, 100)    0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 3640, 100)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 3639, 100)    0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 364100)       0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 364000)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 364000)       0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 363900)       0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1456000)      0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           14560010    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            11          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,574,421\n",
      "Trainable params: 14,574,421\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      " - 134s - loss: 0.7686 - acc: 0.6406\n",
      "Epoch 2/30\n",
      " - 138s - loss: 0.5217 - acc: 0.7313\n",
      "Epoch 3/30\n",
      " - 146s - loss: 0.3636 - acc: 0.8531\n",
      "Epoch 4/30\n",
      " - 128s - loss: 0.2357 - acc: 0.9172\n",
      "Epoch 5/30\n",
      " - 139s - loss: 0.1772 - acc: 0.9297\n",
      "Epoch 6/30\n",
      " - 136s - loss: 0.1127 - acc: 0.9578\n",
      "Epoch 7/30\n",
      " - 160s - loss: 0.0912 - acc: 0.9734\n",
      "Epoch 8/30\n",
      " - 161s - loss: 0.0652 - acc: 0.9828\n",
      "Epoch 9/30\n",
      " - 163s - loss: 0.3110 - acc: 0.9250\n",
      "Epoch 10/30\n",
      " - 166s - loss: 0.2742 - acc: 0.8859\n",
      "Epoch 11/30\n",
      " - 162s - loss: 0.1001 - acc: 0.9719\n",
      "Epoch 12/30\n",
      " - 162s - loss: 0.0654 - acc: 0.9828\n",
      "Epoch 13/30\n",
      " - 162s - loss: 0.0220 - acc: 0.9984\n",
      "Epoch 14/30\n",
      " - 157s - loss: 0.0315 - acc: 0.9938\n",
      "Epoch 15/30\n",
      " - 110s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 16/30\n",
      " - 121s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 17/30\n",
      " - 124s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 18/30\n",
      " - 126s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 19/30\n",
      " - 124s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 20/30\n",
      " - 126s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 21/30\n",
      " - 125s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 22/30\n",
      " - 126s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 23/30\n",
      " - 124s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 24/30\n",
      " - 123s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 25/30\n",
      " - 111s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 26/30\n",
      " - 110s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 27/30\n",
      " - 111s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 28/30\n",
      " - 108s - loss: 0.4353 - acc: 0.9391\n",
      "Epoch 29/30\n",
      " - 106s - loss: 0.3258 - acc: 0.9188\n",
      "Epoch 30/30\n",
      " - 107s - loss: 0.0207 - acc: 0.9906\n",
      "Accuracy: 65.84%\n",
      "Average precision score: 0.53\n",
      "Recall score: 0.45\n",
      "Training session: 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 7283, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 7282, 100)    2100        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 7281, 100)    3100        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 7280, 100)    4100        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 7279, 100)    5100        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 7282, 100)    0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7281, 100)    0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7280, 100)    0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 7279, 100)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 3641, 100)    0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 3640, 100)    0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 3640, 100)    0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 3639, 100)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 364100)       0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 364000)       0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 364000)       0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 363900)       0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1456000)      0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           14560010    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            11          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,574,421\n",
      "Trainable params: 14,574,421\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-968db346c310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlexCnnModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmCreator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateLexCnnMcModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxDim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlexCnnModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Final evaluation of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mlexCnnscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlexCnnModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lexCnnAccuracy = []\n",
    "lexCnnPR = []\n",
    "lexCnnRecall = []\n",
    "for i in range(1):\n",
    "    print(\"Training session: \" + str(i))\n",
    "    #Split data into training and test set (80%/20%)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(np.squeeze(np.stack(lexEmbeddings)), Y, test_size=0.2, shuffle=True, random_state=seed, stratify=Y)\n",
    "    #Create model\n",
    "    lexCnnModel = mCreator.createLexCnnMcModel(maxDim, 10)\n",
    "    # Fit the model\n",
    "    lexCnnModel.fit([xTrain, xTrain, xTrain, xTrain], yTrain, epochs=30, batch_size=3, verbose=2)\n",
    "    # Final evaluation of the model\n",
    "    lexCnnscores = lexCnnModel.evaluate([xTest,xTest,xTest, xTest], yTest, verbose=0)\n",
    "    yPred = lexCnnModel.predict([xTest, xTest, xTest, xTest])\n",
    "    yPredNorm = []\n",
    "    for p in yPred:\n",
    "        if p > 0.5:\n",
    "            yPredNorm.append(1)\n",
    "        else:\n",
    "            yPredNorm.append(0)\n",
    "    lexCnn_average_precision = average_precision_score(yTest, yPred)\n",
    "    lexCnn_recall_score = recall_score(yTest, yPredNorm, average='binary')\n",
    "    print(\"Accuracy: %.2f%%\" % (lexCnnscores[1]*100))\n",
    "    print('Average precision score: {0:0.2f}'.format(lexCnn_average_precision))\n",
    "    print('Recall score: {0:0.2f}'.format(lexCnn_recall_score))\n",
    "    lexCnnAccuracy.append(lexCnnscores[1])\n",
    "    lexCnnPR.append(lexCnn_average_precision)\n",
    "    lexCnnRecall.append(lexCnn_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

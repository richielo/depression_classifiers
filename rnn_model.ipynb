{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import statistics\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import text_features_extractor as tfExtractor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, recall_score\n",
    "#Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import tensorflow\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRnnModel():\n",
    "    #CNN model\n",
    "    rnnModel = Sequential()\n",
    "    rnnModel.add(Embedding(5000, 256, input_length=maxReviewLength))\n",
    "    rnnModel.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    rnnModel.add(MaxPooling1D(pool_size=2))\n",
    "    rnnModel.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    rnnModel.add(Dense(1, activation='sigmoid'))\n",
    "    rnnModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(rnnModel.summary())\n",
    "    return rnnModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model for Chinese data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the csv\n",
    "chinDataDf = pd.read_csv(\"data_with_features/chin_cleaned_data_f.csv\", encoding='UTF-8')\n",
    "#Only take the text and sentiment columns\n",
    "chinDataDf = chinDataDf[['text', 'depressed']]\n",
    "#Cleaning\n",
    "for index, row in chinDataDf.iterrows():\n",
    "    #Preprocessing\n",
    "    chinText, engText = tfExtractor.splitChinEng(row['text'])\n",
    "    text = tfExtractor.chinPreprocessing(chinText)\n",
    "    chinDataDf.set_value(index,'text',text)\n",
    "#Convert data to numpy array\n",
    "X = np.array(chinDataDf['text'].tolist())\n",
    "Y = np.array(chinDataDf['depressed'].tolist())\n",
    "#Convert -1 label to 0\n",
    "i = 0\n",
    "for label in Y:\n",
    "    if(label == -1):\n",
    "        Y[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original number of words: 46708\n",
    "#Set top words\n",
    "topWords = 5000\n",
    "#Tokenizing the data\n",
    "tokenizer = Tokenizer(num_words=topWords)\n",
    "xString = []\n",
    "for text in X:\n",
    "    xString.append(' '.join(text))\n",
    "tokenizer.fit_on_texts(xString)\n",
    "print(\"tokenizer fitting is complete\")\n",
    "xSeq = tokenizer.texts_to_sequences(xString)\n",
    "wordIndex = tokenizer.word_index\n",
    "print(\"Number of words: \" + str(len(wordIndex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get review mean length\n",
    "lengths = [len(i) for i in xSeq]\n",
    "print(\"review mean length: \" + str(np.mean(lengths)))\n",
    "#Set maximum review length to cover at least 90% of review content\n",
    "maxReviewLength = int(np.percentile(lengths, 90))\n",
    "print(\"maximum review length: \" + str(maxReviewLength))\n",
    "\n",
    "#Set paddings for review data\n",
    "xPadded = pad_sequences(xSeq, maxlen=maxReviewLength)\n",
    "print(\"Done padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnAccuracy = []\n",
    "rnnPR = []\n",
    "rnnRecall = []\n",
    "for i in range(10):\n",
    "    print(\"Training session: \" + str(i))\n",
    "    #Split data into training and test set (80%/20%)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xPadded, Y, test_size=0.2, shuffle=True, random_state=i, stratify=Y)\n",
    "    \n",
    "    #Create model\n",
    "    rnnModel = createRnnModel()\n",
    "    \n",
    "    # Fit the model\n",
    "    rnnModel.fit(xTrain, yTrain, validation_data=(xTest, yTest), epochs=50, batch_size=1, verbose=2)\n",
    "    # Final evaluation of the model\n",
    "    rnnscores = rnnModel.evaluate(xTest, yTest, verbose=0)\n",
    "    yPred = rnnModel.predict(xTest)\n",
    "    yPredNorm = []\n",
    "    for p in yPred:\n",
    "        if p > 0.5:\n",
    "            yPredNorm.append(1)\n",
    "        else:\n",
    "            yPredNorm.append(0)\n",
    "    rnn_average_precision = average_precision_score(yTest, yPred)\n",
    "    rnn_recall_score = recall_score(yTest, yPredNorm, average='binary')\n",
    "    print(\"Accuracy: %.2f%%\" % (rnnscores[1]*100))\n",
    "    print('Average precision score: {0:0.2f}'.format(rnn_average_precision))\n",
    "    print('Recall score: {0:0.2f}'.format(rnn_recall_score))\n",
    "    rnnAccuracy.append(rnnscores[1])\n",
    "    rnnPR.append(rnn_average_precision)\n",
    "    rnnRecall.append(rnn_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_mean_ac = float(sum(rnnAccuracy))/float(len(rnnAccuracy))\n",
    "rnn_mean_pr = float(sum(rnnPR))/float(len(rnnPR))\n",
    "rnn_mean_recall = float(sum(rnnRecall))/float(len(rnnRecall))\n",
    "print(\"Overal RNN result\")\n",
    "print(\"accuracy: \" + str(rnn_mean_ac))\n",
    "print(\"precision score: \" + str(rnn_mean_pr))\n",
    "print(\"recall: \" + str(rnn_mean_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
